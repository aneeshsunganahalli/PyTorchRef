# -*- coding: utf-8 -*-
"""PyTorchWorkflow.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ATIms7ORkTxOdNm9N_Fi2BzsyzNHpSRT
"""

# PyTorch Workflow
import torch
from torch import nn
import matplotlib.pyplot as plt

weight = 0.7
bias = 0.3

start = 0
end = 1
step = 0.02
X = torch.arange(start,end,step).unsqueeze(dim=1)
y = weight * X + bias
X[:10], y[:10]

trainSplit = int(0.8 * len(X))
trainSplit

XTrain, YTrain = X[:trainSplit], y[:trainSplit]
XTrain, YTrain

# Linear Regression Model Class
class LinearRegressionModel(nn.Module): # almost everything in PyTorch extends from nn.module (base class being extended)
  def __init__(self):
    super().__init__()
    self.weights = nn.Parameter(torch.randn(1,
                                            requires_grad=True,
                                            dtype=torch.float))
    self.bias = nn.Parameter(torch.randn(1,
                                         requires_grad=True,
                                         dtype= torch.float))

    # Define the computation in the model (in this case linear regression)
  def forward(self, x: torch.Tensor) -> torch.Tensor:
    return self.weights * x + self.bias

torch.manual_seed(42)

model0 = LinearRegressionModel()
list(model0.parameters())

model0.state_dict()

# Predicitions
with torch.inference_mode():
  y_preds = model0(XTrain)

y_preds

# Loss Function
loss_fn = nn.L1Loss()

# Optimizer
optimizer = torch.optim.SGD(params= model0.parameters(),
                            lr= 0.01) # learning rate (very imp hyperparameter)

# Epoch is a loop
epochs = 60

# Track Values
epoch_count = []
loss_values = []
test_loss_values = []

# Loop through data
for epoch in range(epochs):
  model0.train()

  # Foward pass
  y_pred = model0(XTrain)

  # Calculate Loss
  loss = loss_fn(y_pred, YTrain)
  print(f"Loss: {loss}")

  # Optimizer zero grad
  optimizer.zero_grad()

  # Perform Back Propogation
  loss.backward()

  # Step the optimizer (perform gradient descent)
  optimizer.step()

  model0.eval()
  with torch.inference_mode():
    test_pred = model0(XTrain)

    testLoss = loss_fn(test_pred, YTrain)
    if epoch % 10 == 0:
      epoch_count.append(epoch)
      loss_values.append(loss)
      test_loss_values.append(testLoss)
      print(f"Epoch: {epoch} | Loss: {loss} | Test loss: {testLoss}")
      print(model0.state_dict())
  print(model0.state_dict())

import numpy as np
plt.plot(epoch_count, np.array(torch.tensor(loss_values).numpy()), label="Train loss")
plt.plot(epoch_count, test_loss_values, label="Test loss")
plt.title("Training and test loss curves")
plt.ylabel("Loss")
plt.xlabel("Epochs")
plt.legend();

with torch.inference_mode():
  y_preds_new = model0(XTrain)

model0.state_dict()

from pathlib import Path

MODEL_PATH = Path("models")
MODEL_PATH.mkdir(parents=True, exist_ok=True)

MODEL_NAME = "01PyTorch.pth"
MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME

MODEL_SAVE_PATH

print(f"Saving model to : {MODEL_SAVE_PATH}")
torch.save(obj=model0.state_dict(), f=MODEL_SAVE_PATH)

!ls -l models

loaded_model = LinearRegressionModel()
loaded_model.load_state_dict(torch.load(f=MODEL_SAVE_PATH))

loaded_model.state_dict()

import torch
from torch import nn
import matplotlib.pyplot as plt

torch.__version__

device = "cuda" if torch.cuda.is_available() else "cpu"
print(device)

